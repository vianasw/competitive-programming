{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem definition: https://adventofcode.com/2018/day/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.succ = []\n",
    "        self.pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(filename):\n",
    "    f = open(filename, 'r')\n",
    "    nodes = {}\n",
    "    for line in f:\n",
    "        parts = line.split(' ')\n",
    "        orig_key = parts[1]\n",
    "        dest_key = parts[7]\n",
    "        \n",
    "        if orig_key in nodes:\n",
    "            orig = nodes[orig_key]            \n",
    "        else:\n",
    "            orig = Node(orig_key)\n",
    "            \n",
    "        if dest_key in nodes:\n",
    "            dest = nodes[dest_key]            \n",
    "        else:\n",
    "            dest = Node(dest_key)\n",
    "        \n",
    "        orig.succ.append(dest)\n",
    "        dest.pred.append(orig)\n",
    "        \n",
    "        if orig_key not in nodes:\n",
    "            nodes[orig_key] = orig\n",
    "        \n",
    "        if dest_key not in nodes:\n",
    "            nodes[dest_key] = dest\n",
    "    \n",
    "    # pre-calculate node traversal order here by sorting successors list\n",
    "    for k, node in nodes.items():\n",
    "        node.succ = sorted(node.succ, key = lambda n: n.key, reverse=True)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is solved with a topological sort algorithm (https://en.wikipedia.org/wiki/Topological_sorting). I incidentally implemented something similar to the Kahn's algorithm but without modifying the original graph by removing its edges. Instead I use a visited set data structure to know if the node can be visited or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(nodes):\n",
    "    available = find_available(nodes)\n",
    "\n",
    "    stack = available\n",
    "    visited = set()\n",
    "    order = []\n",
    "    while stack:\n",
    "        cur_node = stack.pop()\n",
    "        visited.add(cur_node)\n",
    "        order.append(cur_node)\n",
    "\n",
    "        for s in cur_node.succ:\n",
    "            if s not in visited and set(s.pred).issubset(visited):\n",
    "                append_lexicographically(stack, s)\n",
    "\n",
    "    if len(order) == len(nodes):\n",
    "        return [node.key for node in order]\n",
    "    return []\n",
    "\n",
    "def find_available(nodes):\n",
    "    available = []\n",
    "    for k, node in nodes.items():\n",
    "        if not node.pred:\n",
    "            available.append(node)\n",
    "    return sorted(available, key=lambda c: c.key, reverse=True)\n",
    "\n",
    "def append_lexicographically(stack, s):\n",
    "    stack2 = []\n",
    "    while stack and s.key > stack[-1].key:\n",
    "        stack2.append(stack.pop())\n",
    "    stack.append(s)\n",
    "    while stack2:\n",
    "        stack.append(stack2.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = build_graph('example1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'A', 'B', 'D', 'F', 'E']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topological_sort(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AHJDBEMNFQUPVXGCTYLWZKSROI'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = build_graph('input.txt')\n",
    "order = topological_sort(nodes)\n",
    "''.join(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing my solution I found out that it could be solved in just two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHJDBEMNFQUPVXGCTYLWZKSROI\n"
     ]
    }
   ],
   "source": [
    "from networkx import DiGraph, lexicographical_topological_sort as lt_sort\n",
    "\n",
    "print(''.join(lt_sort(DiGraph((line.split()[1], line.split()[-3]) for line in open('input.txt', 'r')))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 is just a slight modification of the topological_sort method:\n",
    "* Keep track of the available workers\n",
    "* Store the remaining amount of time for each task being executed in parallel, and update it on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_completion_time(nodes, num_workers, task_time):\n",
    "    available = find_available(nodes) \n",
    "    stack = available\n",
    "    visited = set()\n",
    "    order = []\n",
    "    available_workers = num_workers\n",
    "    cur_nodes = {}\n",
    "    tic = 0\n",
    "    while len(order) != len(nodes):\n",
    "        while available_workers > 0 and stack:            \n",
    "            node = stack.pop()\n",
    "            cur_nodes[node] = task_time + ord(node.key) - ord('A') + 1\n",
    "            available_workers -= 1\n",
    "        \n",
    "        tic += 1\n",
    "        completed_buffer = []\n",
    "        for node, _ in cur_nodes.items():\n",
    "            cur_nodes[node] -= 1\n",
    "            if cur_nodes[node] == 0:\n",
    "                available_workers = min(num_workers, available_workers + 1)\n",
    "                visited.add(node)\n",
    "                order.append(node)\n",
    "\n",
    "                for s in node.succ:\n",
    "                    if s not in visited and set(s.pred).issubset(visited):\n",
    "                        append_lexigrophically(stack, s)\n",
    "                \n",
    "                completed_buffer.append(node)\n",
    "                \n",
    "        for node in completed_buffer:\n",
    "            del cur_nodes[node]\n",
    "\n",
    "    return tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = build_graph('input.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1031"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_completion_time(nodes, 5, 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
